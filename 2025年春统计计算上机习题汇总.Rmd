---
title: "统计计算上机习题汇总"
author: '曹哲涵'
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    mathjax: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
library(tidyverse)
```

# 第二章

## 第一次作业

### 问题1
&emsp;&emsp;编写eg2.1.10中的组合发生器产生1000个随机数（自己给定初值进行测试）。
```{r}
input=c(5,2,0)
manual_runif=function(input,n=1000){
if (n == 0) {return(numeric(0))}
new=(input*c(171,172,170))%%c(30269,30307,30323)
r=sum(new/c(30269,30307,30323))%%1
return(c(r,manual_runif(new,n-1)))
}
dat=manual_runif(input)
head(dat,20)
```

### 问题2

&emsp;&emsp;分别编写参数检验（课本检验1，只对均值进行检验即可）、拟合优度卡方检验程序（分20组），并分别利用runif函数和题目1中生成的随机数进行测试。

&emsp;&emsp;生成的随机数独立同分布，当数量很多时可以采用中心极限定理知和函数近似服从正态分布，$X\sim U(0,1)$，$Var(\bar X)=\sqrt{\frac{1}{12n}}$因此，因此$\sqrt{12n}(\bar X -\frac{1}{2})\dot  \sim N(0,1)$。原假设:$\bar x$的均值是1/2。备择假设：$\bar x$的均值不是1/2。
```{r}
rand_test=function(dat){
result=list()
n=length(dat)
z=sqrt(12*n)*(mean(dat)-1/2)
result$z=z>=qnorm(0.975)
result$p=2*pnorm(z,lower.tail=FALSE)
return(result)
}
print(rand_test(dat))
```
&emsp;&emsp;从假设检验的结果上看，无法拒绝原假设，因而我们认为$\bar x$的均值是1/2。即原序列是随机的。

&emsp;&emsp;卡方检验统计量的构造：$T=\sum\limits_{i = 1}^m {\frac{{({n_i} - n{p_i})}}{{n{p_i}}}} \mathop  \to \limits^L {\chi ^2}(m - 1)$

```{r}
rand_chisq=function(dat,m=20){
n=length(dat)
left_inter=rep(1,n)%*%t(seq(0,1,by=1/m)[1:m])
right_inter=rep(1,n)%*%t(seq(0,1,by=1/m)[2:(m+1)])
A=dat>=left_inter&dat<=right_inter
frequ=apply(A,2,sum)
stat=m/n*sum((frequ-n/m)^2)
result=list()
#chisq.test(frequ)
result$z=stat>qchisq(0.95,m-1)
result$p=pchisq(stat,m-1,lower.tail = F)
result
}
rand_chisq(dat)
```
&emsp;&emsp;p=0.419，无法拒绝原假设，因而可以认为随机数在各个区间的分布是随机的。

&emsp;&emsp;采用内置均匀随机数发生器检验上面的函数。
```{r}
set.seed(222)
data=runif(1000)
rand_test(data)
rand_chisq(data)
```

&emsp;&emsp;自带的随机数生成器unif生成的随机数足够随机。

### 问题3

&emsp;&emsp;使用ks.test()检验题目1中的随机数是否符合要求。
```{r}
 ks.test(dat, "punif", min = 0, max = 1)
```
&emsp;&emsp;结果说明我们产生的随机数足够随机，符合要求。

### 问题4
&emsp;&emsp;用如下方法编写正态随机数生成（每种算法生成10^6个N(0,1)随机数，比较算法的效率（比较运行时间））

#### 方法1：Box-muler方法

```{r}
system.time({U1=runif(5e+5)
U2=runif(5e+5)
X=sqrt(-2*log(U1))*cos(2*pi*U2)
Y=sqrt(-2*log(U1))*cos(2*pi*U2)
rand=c(X,Y)})
```

#### 方法2：极坐标+舍选法

&emsp;&emsp;利用单位圆上的均匀分布

```{r}
system.time(
{set.seed(999)
r=c()
n=1e+3
for (ii in (1:n)){
  repeat{
  U=runif(2)
  V=2*U-1
  S=sum(V^2)
  if(S<=1){
    r=c(r,sqrt(-2*log(S)/S)*V)
    break
  }
}
}
print(head(r,10))
hist(r)
})
```
单纯用极坐标+舍选法的速度比较慢，由于采样的效率是$\frac{1}{\pi}$，每次生成2个，平均每1.5个钟有一个满足要求。经测试生成满足要求的个数大约需要2分钟。

#### 方法3：逆变换法

&emsp;&emsp;标准Cauchy分布作为建议分布，cauchy随机数由逆变换产生。变换公式为$\tan(\pi(x-\frac{1}{2}))$
```{r}
r=runif(1e+4)
X=tan((r-0.5)*pi)
ks.test(X,"pcauchy")
rcauchy_manual=function(n){
  r=runif(n)
  return(tan((r-0.5)*pi))
}

rnorm_manual=function(){
  repeat{
  X=rcauchy_manual(1)
  Y=runif(1,0,1)
  accept_prob = exp(-X^2/2) * (1 + X^2) / sqrt(2*pi) * sqrt(2*pi/exp(1))
  if (Y<= accept_prob){break}
  }
  return(X)
}
x=replicate(1000,rnorm_manual())
hist(x)
ks.test(x,"pnorm",0,1)
```

#### 方法4：逆变换法产生指数分布

&emsp;&emsp;Exp(1)作为试投，指数分布随机数由逆变换法生成。变换公式为$-\ln(1-r)$,其中r是(0,1)上均匀分布产生的随机数。
```{r}
system.time({r=runif(1e+3)
X=-log(1-r)
hist(X)})

exp_manual=function(n,lambda=1){
  r=runif(n)
  return(X=-1/lambda*log(r))
}

rnorm_manual=function(){
  c=sqrt(2/pi)*exp(1/2)
  repeat{
  x=exp_manual(1,lambda = 1)
  Y=runif(1,0,1)
  accept_prob=sqrt(2/pi)*exp(-x^2/2+x)/c
  if (Y<= accept_prob){break}
  }
  r=sample(c(1,-1),1)
  return(r*x)
}
x=replicate(1000,rnorm_manual())
hist(x)
ks.test(x,"pnorm",0,1)
```

## 第二次作业

### 1、课后题 26
多项超几何分布数值模拟
输入：一个向量，向量每个元素是每种颜色球的个数，无放回抽出m个球，每类球的个数符合超几何分布。
```{r}
#模拟2类时的超几何分布
#第一类是a个，剩余一类n-a个，取m个
jihe=function(a,n,m){
return(sum(sample(rep(c(T,F),c(a,n-a)),m,replace = F)))
}
jihe(a=20,n=100,m=10)
#再以此模拟每个分量
hyper=function(all,n){
hyper=c(0)
for (ii in 1:length(all)){
  hyper[ii]=jihe(all[ii],sum(all[ii:length(all)]),n-sum(hyper))
}
hyper[length(all)]=n-sum(hyper[1:length(all)-1])
#可能存在要修正的情况,只使用于抽取个数相比于每组个数很少的情况
return(hyper)}
all=c(10,20,30)
n=10
hyper(all,n)
all=c(10,20,22,50,60)
n=60
hyper(all,n)

#改进版本，考虑了类别数目少于剩余抽样样本数的情况,考虑了最后一个个数不足的情况，比较稳健
hyper = function(all, n) {
  hyper = numeric(length(all))  # 初始化结果向量
  remaining_total = sum(all)    # 初始剩余总样本数
  remaining_sample = n          # 初始剩余待抽样本数
  for (ii in 1:(length(all) - 1)) {
    if (remaining_total == 0 || remaining_sample == 0) {
      hyper[ii] = 0
    } else {
      hyper[ii] = jihe(
        a = all[ii],
        n = sum(all[ii:length(all)]), 
        m = remaining_sample
      )
    }
    remaining_total = remaining_total - all[ii]  
    remaining_sample = remaining_sample - hyper[ii]  
  }
  # 最后一组直接取剩余样本数
  hyper[length(all)] = remaining_sample
  return(hyper)
}
all=c(10,20,22,50,2)
n=60
hyper(all,n)
```

### 第二题

2、 分别利用条件分布法和变换法（即协方差矩阵分解对应的算法）生成二元正态分布N(u1,u2,sigma1^2,sigma^2,rho)
```{r}
#条件分布法
mu=c(1,1)
cm=matrix(c(1, 0.5, 0.5, 2), 2, 2)
norm1 <- function(mu, cm, n = 1) {
  rho <- cm[1, 2] / sqrt(cm[1, 1] * cm[2, 2])
  
  y1 <- rnorm(n, mu[1], sqrt(cm[1, 1]))
  y2 <- rnorm(n, mu[2] + rho * sqrt(cm[2, 2]/cm[1, 1]) * (y1 - mu[1]),sqrt(cm[2, 2] * (1 - rho^2)))
  
  cbind(y1, y2)
}
samples <- norm1(mu, cm, n = 1000)  
plot(samples[,1],samples[,2])
#变换法
library(MASS)
n=1000
mu=c(1,1)
cm=matrix(c(1, 0.5, 0.5, 2), 2, 2)
mnorm=function(n,mu,cm){
z=mvrnorm(n,mu = c(0,0), Sigma=matrix(c(1,0, 0,1), 2, 2))
t(chol(cm))%*%t(z)+mu}
mm=mnorm(n,mu,cm)
plot(mm[1,],mm[2,])
```


### 第三题
 编写生成参数为lamba 的泊松过程在时刻T前状态的程序。
```{r}
lambda=0.5
T=100
pois=function(lambda,T){
t=numeric()
while(sum(t)<=T){
  t=c(t,rexp(1,lambda))
}
return(cumsum(t[-length(t)]))
}
pois(lambda=0.5,T=100)
```

# 第三章

## 第三次作业

### 第一题

1、利用以下方法编程实现“pai”的估计，并比较各估计的方差。（样本量N=10000，每种方法重复B=1000次用于计算方差） （1）随机投点法；（2）平均值法
```{r}
pai_suiji=function(N=10000){
  points=data.frame(x=runif(N,0,1),y=runif(N,0,1))
  points=points%>%mutate(z=x^2+y^2,t=z<1)
  return(sum(points$t)/N*4)
}
results <- replicate(100, pai_suiji())
cat(mean(results))
cat(var(results))

pai_pingjun=function(N=10000){
  x=runif(N)
  return(mean(4*sqrt(1-x^2)))
}
results <- replicate(100,pai_pingjun())
cat(mean(results))
cat(var(results))
```
虽然都是无偏估计，但是从方差来看，高下立判。

### 第二题

2、例题3.2.2 对比网格点法和随机模拟积分的精度。
```{r}
n=5
d=8
I=(1/3)^d
shuzhi=function(n=5,d=8){
  N=n^d
  len=seq(0,1,length.out=5)
  x=expand.grid(rep(list(len), d))
  x %>% mutate(z = Reduce(`*`, across(everything())))%>%summarise(t=sum(z)/N)%>%as.numeric()
}
I-shuzhi()
pj=function(d=8,N=100000){
  len=matrix(runif(d*N,0,1)^2,nrow=N)
  mean(apply(len,1,prod))
}
pj()
I
I-pj()
```
### 第三题

3、例题3.2.3 & 3.2.4 &3.2.5(数据见习题三.8)实现

```{r}
I=exp(1)-1
N=10000
r=runif(N,0,1)
rr=sqrt(1+3*r)-1
mean(exp(1)^rr/(2/3*(1+rr)))
```

```{r}
library(MASS)
d1=function(){
mu1 <- c(-0.4, 0.5) 
sigma1 <- matrix(c(1/90, 0, 0, 1/120), nrow = 2)
r1=mvrnorm(1,mu1,sigma1)
mu2 <- c(0.5, -0.1) 
sigma2 <- matrix(c(1/180, 0, 0, 1/20), nrow = 2)
r2=mvrnorm(1,mu2,sigma2)
r=runif(1,0,1)
if(r<0.5358984){return(r1)}
else return(r2)}
dd=as.data.frame(t(replicate(1000,d1())))
mean(exp(-45*(dd$V1+0.4)^2-60*(dd$V2-0.5)^2)+0.5*exp(-90*(dd$V1-0.5)^2-45*(dd$V2+0.1)^4)/(
  0.5358984*sqrt(2*pi/90)*sqrt(2*pi/120)*exp(-45*(dd$V1+0.4)^2-60*sqrt(2*pi/180)*sqrt(2*pi/20)*(dd$V2-0.5)^2)+(1-0.5358984)*exp(-90*(dd$V1-0.5)^2-10*(dd$V2+0.1)^2)))
```

```{r}
dbetabin <- function(y, n, K, eta){
  choose(n, y)*beta(K*eta + y, K*(1-eta) + n-y)/beta(K*eta, K*(1-eta))
}
p.post <- function(a, b){
  K <- exp(a)
  eta <- 1/(1 + exp(-b))
  val <- K / (1+K)^2
  beta0 <- beta(K*eta, K*(1-eta))
  for(j in seq(n)){
    val <- val * beta(K*eta + yarr[j], K*(1-eta) + narr[j] - yarr[j]) / beta0
  }
  val[beta0==0] <- 0
  val
}
set.seed(1)
K.true <- 10
eta.true <- 0.2
narr <- c(20, 30, 25, 30, 40, 20, 50, 30, 20, 20)
yarr <- c( 3,  2,  6, 12,  6,  8, 22,  8,  5,  2)
set.seed(1)
N <- 10000
df.t <- 4
alpha.samp <- rt(N, df.t)
beta.samp <- rt(N, df.t)
wei <- p.post(alpha.samp, beta.samp) / dt(alpha.samp, df.t) / dt(beta.samp, df.t)
est <- sum(alpha.samp*wei) / sum(wei)
log(K.true)
est
wei <- wei/sum(wei)*N
summary(wei)
boxplot(wei)
```

### 第四题
4、利用重要性采样法估计概率P(X>20),X~N(0,1), 使用倾斜分布ft作为提议分布，ft~N(t,1)（ 样本量N=10000 ）,并估算估计的标准差（重复B=1000次）;对比不同t对估计结果以及标准差的影响。
```{r}
set.seed(123)  
N <- 10000     
t <- 20       
x_samples <- rnorm(N, mean = t, sd = 1)
w <- dnorm(x_samples, mean = 0, sd = 1) / dnorm(x_samples, mean = t, sd = 1)
#估计 P(X > 20) = E[I(X > 20) * w(X)]，不能删去
indicator <- ifelse(x_samples > 20, 1, 0)
P_estimate <- mean(indicator * w)
print(P_estimate)

##计算误差
B<-100
estimates <- numeric(B) 
#把上面的过程写成函数
p_estimate=function(t,N){
  x_samples <- rnorm(N, mean = t, sd = 1)
  w <- dnorm(x_samples, mean = 0, sd = 1) / dnorm(x_samples, mean = t, sd = 1)
  indicator <- ifelse(x_samples > t, 1, 0)
  return(mean(indicator * w))
}
estimates=replicate(B,p_estimate(20,N))
sd(estimates)

t_values <- c(18, 19, 20, 21, 22)  
results <- data.frame(t = numeric(), estimate = numeric(), sd = numeric())

for (t in t_values) {
  estimates=replicate(B,p_estimate(20,N))
  results <- rbind(results, data.frame(t = t, estimate = mean(estimates), sd = sd(estimates)))
}
# 输出结果
knitr::kable(results,digits = 100)
```
```{r,echo=F,eval=F}
library(ggplot2)
library(scales) 

# 自定义主题 - 专业学术风格
professional_theme <- function() {
  theme_minimal(base_size = 12) +
    theme(
      text = element_text(family = "sans", color = "#333333"),
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5, margin = margin(b = 20)),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text = element_text(size = 10),
      panel.grid.major = element_line(color = "gray90", linewidth = 0.2),
      panel.grid.minor = element_blank(),
      plot.margin = margin(20, 20, 20, 20),
      legend.position = "top",
      legend.title = element_text(face = "bold")
    )
}

# 估计值可视化
p1 <- ggplot(results, aes(x = t, y = estimate)) +
  geom_line(color = "#1f77b4", linewidth = 1.2) +
  geom_point(color = "#1f77b4", size = 3, shape = 19) +
  scale_y_continuous(labels = scientific_format(digits = 2)) +
  labs(title = "重要性采样估计结果",
       subtitle = expression(paste("P(X > 20) where X ~ N(0,1)")),
       x = "倾斜参数 (t)",
       y = "概率估计值") +
  professional_theme()

# 标准差可视化
p2 <- ggplot(results, aes(x = t, y = sd)) +
  geom_line(color = "#ff7f0e", linewidth = 1.2) +
  geom_point(color = "#ff7f0e", size = 3, shape = 17) +
  scale_y_continuous(labels = scientific_format(digits = 2)) +
  labs(title = "估计值的标准差",
       subtitle = "基于1000次重复实验",
       x = "倾斜参数 (t)",
       y = "标准差") +
  professional_theme()

# 组合图表
library(patchwork)
combined_plot <- p1 / p2 + 
  plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(size = 14, face = "bold"))

# 输出高质量图表
print(combined_plot)

# 保存为高分辨率图片
#ggsave("importance_sampling_results.png", 
       plot = combined_plot,
       width = 8, height = 8, 
       dpi = 300, bg = "white")
```

![](importance_sampling_results.png)

## 第四次作业

### 估计 pai

1、利用以下方法编程实现$\pi$的估计，并比较各估计的方差。（样本量N=10000） （1）随机投点法；（2）平均值法；（3）随机投点+条件期望法（4）随机投点+条件期望法+对立变量法（5） 随机投点+ 条件期望法+控制变量（分别用U和U\^2作为控制变量）

```{r}
library(pacman)
p_load(tidyverse,rio)
#随机投点
n=10000
x=runif(n,0,1)
y=runif(n,0,1)
z=sum((x^2+y^2)<=1)/n*4
print(z)
#平均值法
x=runif(n,0,1)
y=sum(sqrt(1-x^2))/n*4
print(y)
#随机投点+条件期望
x=runif(n,0,1)
y=mean(sqrt(1-x^2))*4
print(y)
#随机投点+条件期望法+对立变量法
x=runif(n,0,1)
mean((sqrt(1-x^2)+sqrt(1-(1-x)^2))/2)*4
#随机投点+ 条件期望法+控制变量（分别用U和U^2作为控制变量）
x=runif(n,0,1)
b=-cov(sqrt(1-x^2),x-1/2)/var(x)
mean(sqrt(1-x^2)+b*(x-1/2))*4

x=runif(n,0,1)
yy=x^2
m=1/3
mean(sqrt(1-x^2))*4
b=-cov(sqrt(1-yy^2),yy-m)/var(yy)
mean(sqrt(1-x^2)+b*(yy-m))*4
```

![](bridge_structure.jpg)

### 系统稳定性
2、附件是某系统的结构图，利用Mont Carlo 方法估计该系统的可靠性。并利用对立变量和控制变量法改进其方差。（假设每个元件独立，正常工作的概率都是0.8）

正常工作概率大约是0.91
```{r}
p=0.8
fact=p*(1-(1-p)^2)^2+(1-p)*(1-(1-p^2)^2)
print(fact)
n=10000
state=c(1,1,0,0,1)
WorkState=function(state){
  state_matrix <- matrix(c(1, 0, 1, 0, 1,
                         0, 1, 1, 1, 0,
                         0, 1, 0, 0, 1,
                         1, 0, 0, 1, 0), 
                       nrow = 4, ncol = 5, byrow = TRUE)
  state <- matrix(rep(state,4),nrow = 4, ncol = 5, byrow = TRUE)
  return(sum(rowSums((state-state_matrix)>=0)==5)>0)
}
WorkState(state)
#Mont Carlo 方法估计该系统的可靠性
data=matrix(sample(c(1,0),5*n,c(0.8,0.2),replace=T),nrow = n,ncol=5,byrow=T)
result <- map_vec(1:nrow(data), ~ WorkState(data[.x, ]))
#result <- apply(data, 1, WorkState)
mean(result)
#用对立变量
data=matrix(runif(5*n),nrow = n,ncol=5,byrow=T)<=0.8
data1=matrix(1,nrow = n,ncol=5,byrow=T)-data<=0.8
result <- map_vec(1:nrow(data), ~ WorkState(data[.x, ]))+ map_vec(1:nrow(data1), ~ WorkState(data1[.x, ]))
mean(result/2)
#控制变量法
#先进行系数估计
m <- 10000
data_control <- matrix(runif(5 * m) <= 0.8, nrow = m, ncol = 5)
X <- apply(data_control, 1, WorkState)#通常情况下，和越大，越有可能是满足条件
Y <- rowSums(data_control)
c <- -cov(X, Y) / var(Y)
#再采用控制变量法进行模拟
data_est <- matrix(runif(5 * n) <= 0.8, nrow = n, ncol = 5)
X_est <- apply(data_est, 1, WorkState)
Y_est <- rowSums(data_est)
hat_r <- mean(X_est + c * (Y_est - 4))
print(hat_r)
```

## 第五次作业

### 例3.7.1

```{r,eval=FALSE}
# MCMC方法
n <- 4
a <- 0
times <- 1000

MCMC_zuhe <- function(n, a, times) {
  if (a <= sum(c(1:n) * c(n:1))) {
    cat("任意组合都满足条件，不需要MCMC")
  } else if (a >= sum(c(1:n)^2)) {
    cat("没有满足条件的组合，请检查输入")
  } else {
    cat("正在初始化采样点\n")}
    repeat{
      # 初始化满足条件的样本点
      ii <- sample(n)
      if (sum(ii * c(1:n)) > a) {
        break
      }
    }
    MH <- matrix(t(ii), nrow = 1)
    #开始循环抽样
    for (t in 2:times) {
      # 随机打乱两个位置
      id <- sample(1:n, 2,replace = F)
      shuffle <- function(ii, id) {
        ii[id] <- ii[rev(id)]
        return(ii)
      }
      ii_after <- shuffle(ii,id)
      # 计算某一组合所有的满足条件的近邻的个数
      An <- function(ii_after) {
        aa <- expand.grid(c(1:n), c(1:n))
        aa <- aa[aa$Var1 < aa$Var2, ]
        results <- map2_vec(
          .x = aa$Var1,
          .y = aa$Var2,
          .f = ~ {
            shuffled <- shuffle(ii_after, c(.x, .y))
            sum(shuffled * 1:n) > a # 返回逻辑值
          }
        )
        aa <- aa[which(results == T), ]
        return(nrow(aa))
      }
      alpha <- min(1, An(ii) / An(ii_after))
      u <- runif(1,0,1)
      if (u <= alpha&(sum(ii_after*(1:n))>a)) {
        ii <- ii_after
      } else {
        ii <- ii
      }
      MH <- rbind(MH, ii)
      if (t %% 1000 == 0) cat("已完成", t, "次迭代\n")
    }
  return(MH)
}
MC <- MCMC_zuhe(n,a, times)
MC=MC[(0.5*nrow(MC)):(nrow(MC)), ]

#有些近邻会出现问题：没有满足要求的近邻
if(is.matrix(MC)) {
  combo_strings <- apply(MC, 1, function(x) paste(x, collapse = ","))
  
  # 计算每种组合出现的频率
  combo_counts <- table(combo_strings)
  
  # 转换为数据框并排序
  freq_table <- data.frame(
    Combination = names(combo_counts),
    Count = as.numeric(combo_counts),
    stringsAsFactors = FALSE
  )
  
  # 按出现次数降序排列
  freq_table <- freq_table[order(-freq_table$Count), ]
  
  # 计算比例
  freq_table$Proportion <- freq_table$Count / sum(freq_table$Count)
} 

#-----------------------------------------------------
MCMC_zuhe <- function(n, a, times) {
  if (a <= sum(c(1:n) * c(n:1))) {
    cat("任意组合都满足条件，不需要MCMC")
  } else if (a >= sum(c(1:n)^2)) {
    cat("没有满足条件的组合，请检查输入")
  } else {
    cat("正在初始化采样点\n")}
    repeat{
      # 初始化满足条件的样本点
      ii <- sample(n)
      if (sum(ii * c(1:n)) > a) {
        break
      }
    }
    MH <- matrix(t(ii), nrow = 1)
    #开始循环抽样
    for (t in 2:times) {
      # 随机打乱两个位置
      id <- sample(1:n, 2,replace = F)
      shuffle <- function(ii, id) {
        ii[id] <- ii[rev(id)]
        return(ii)
      }
      ii_after 
      # 计算某一组合所有的满足条件的近邻的个数
      An <- function(ii_after) {
        aa <- expand.grid(c(1:n), c(1:n))
        aa <- aa[aa$Var1 < aa$Var2, ]
        results <- map2_vec(
          .x = aa$Var1,
          .y = aa$Var2,
          .f = ~ {
            shuffled <- shuffle(ii_after, c(.x, .y))
            sum(shuffled * 1:n) > a # 返回逻辑值
          }
        )
        aa <- aa[which(results == T), ]
        return(aa)
      }
      before=An(ii)
      ii_after=sample(1:nrow(before),1)
      alpha <- min(1, nrow(before)/nrow(An(ii_after)))
      u <- runif(1,0,1)
      if (u <= alpha) {
        ii <- ii_after
      } else {
        ii <- ii
      }
      MH <- rbind(MH, ii)
      if (t %% 1000 == 0) cat("已完成", t, "次迭代\n")
    }
  return(MH)
}
```

### 例题3.7.3
```{r}
#随机游走
A=20
B=10
d=1
K=11
v=1
time=100
#检查所有的圆心是否满足条件
dis_judge=function(x,y,d=1){
  df=data.frame(x=x,y=y)
  dis=dist(df,method="euclidean")
  return(all(dis>=1))
}
#初始化
repeat{
x=runif(K,0,A)
y=runif(K,0,B)
if(dis_judge(x,y))break
}
MH_x <- matrix(t(x), nrow = 1)
MH_y <- matrix(t(x), nrow = 1)
for(t in 2:time){
eps=rnorm(2,0,v)
ii=sample(K)
x_new=x
y_new=y
x_new[ii]=x[ii]+eps[1]
y_new[ii]=y[ii]+eps[2]
if(dis_judge(x,y)){
  x=x_new
  y=y_new
}
MH_x <- rbind(MH_x,x)
MH_y <- rbind(MH_y,x)
}
```

### 习题3.21

```{r}
x=c(82,72,45,34,17)
beta0=0.3
time=1000
beta=beta0
B=c(beta)
for(t in 2:time){
  y=runif(1,0,0.5)
  mu=(((1-y)/(1-beta))^(x[2]))*((1-2*y)/(1-2*beta)^(x[3]))*((y/beta)^(x[4]+x[5]))
  r=min(1,mu)
  z=runif(1,0,1)
  if(z<=r){beta=y}
  B=c(B,beta)
}
mean(B)
plot(B,type = 'l')

```

### 例题3.7.4
```{r}
#二元正态分布的Gibbs采样
pho=0.8
n=5000
zt=matrix(c(0,0),nrow = n + 1,ncol=2,byrow = T)
colnames(zt)=c('x','y')
for(ii in 1:n){
  zt[ii+1,1]=rnorm(1,pho*zt[ii,2],1-pho^2)
  zt[ii+1,2]=rnorm(1,pho*zt[ii+1,1],1-pho^2)
} 
plot(zt)
```

### 习题28粒子滤波
```{r}
set.seed(123)
phi=0.6
v_yita=1/6
A=320
f=1.072e7
v_ep=1
n=300
N=1000     #粒子数目
x <- c(0, numeric(n)) 
for (i in 1:n) x[i+1] <- phi * x[i] + rnorm(1, sd = sqrt(v_yita))
x=x[-1]
y=A*cos(f*c(1:n)+x)+rnorm(n,0,sqrt(v_ep))
#-----------------------------------------------------
#画图的程序
lineplot=function(data,t){
  data_long <- pivot_longer(
    data,
    cols = -!!sym(t),               
    names_to = "变量",   
    values_to = "value"      
  )
  ggplot(data_long, aes(x = t, y = value, color = 变量)) +
    geom_line(linewidth = 0.8) +
    labs(title = "", x = "t", y = "") +
    theme_classic()+
    scale_x_continuous(expand = c(0, 0)) +  
    #scale_y_continuous(expand = c(0, 0))+
    theme(
      axis.line.x = element_line(
        arrow = arrow(length = unit(0.3, "cm"), type = "open")
      ),
      axis.line.y = element_line(
        arrow = arrow(length = unit(0.3, "cm"), type = "open")
      )
    ) 
}

#-----------------------------------------------------
#粒子滤波+重采样
simple_resample=function(particles,weights){
  l=length(particles)
  id=sample(1:l,prob=weights,replace=T)
  particles_new=particles[id]
  weights_new=rep(1/l,l)
  return(list(particles_new,weights_new))
}

X <- matrix(0,nrow=n,ncol=N)
weights <- matrix(0, n, N)
X[1, ] <- rnorm(N,0,sqrt(v_yita))
weights[1, ] <- 1/N
x_est=numeric(n)
for (t in 2:n) {
  X[t,]=phi*X[t-1,]+rnorm(N,0,sqrt(v_yita))
  mu <- A * cos( f * t + X[t, ])
  likelihoods <- dnorm(y[t], mu, sqrt(v_ep))
  weights[t, ] <- weights[t - 1, ] * likelihoods
  weights[t, ] <- weights[t, ] / sum(weights[t, ])
  #重采样
  rs=simple_resample(X[t,],weights[t, ])
  X[t,]=rs[[1]]
  weights[t, ]=rs[[2]]
  x_est[t] <- sum(X[t, ] * weights[t, ])
}
dat=data.frame(t=1:n,真实值=x,观测值=x_est)  
lineplot(dat,'t')
```

## 习题三剩余习题

### 习题三16题

检验方法的功效对比

```{r}
fun1=function(x,y,alpha){
t=mean(y)/sqrt(1/length(y)*var(y))
return(abs(t)>qt(1-alpha/2,n-1))}

fun2=function(x,y,alpha){
  b_hat=sum(x*y)/sum(x^2)
  U=b_hat^2*sum(x^2)
  Q=sum(y^2)-U
  F=U/Q*(length(y)-1)
  return(F>qf(1-alpha,1,length(y)-1))}

b=c(0,0.01,0.05,seq(0.1,0.5,0.1))
l=length(b)
v=1
n=100
alpha=0.05
sim_num <- 2000
result_fun <- data.frame(
  b = numeric(sim_num * length(b)),
  fun1 = logical(sim_num * length(b)),
  fun2 = logical(sim_num * length(b))
)
row_index <- 1
for (bb in b) {
  for (i in 1:sim_num) {
    x <- rexp(n, 1)
    epsilon <- rnorm(n, 0, sqrt(v))
    y <- x * bb + epsilon
    
    result_fun[row_index, "b"] <- bb
    result_fun[row_index, "fun1"] <- fun1(x, y, alpha)
    result_fun[row_index, "fun2"] <- fun2(x, y, alpha)
    
    row_index <- row_index + 1
  }
}
result_fun %>%
  group_by(b) %>%
  summarise(
    mean_fun1 = mean(fun1),
    mean_fun2 = mean(fun2)
  )

```

### 习题18

boostrap方法比较

```{r}
#习题18
A=10
b=1
v=20
x=seq(-10,10)
n=length(x)
ep=rnorm(n,0,v)
#ep=rnorm(n,0,abs(x)) #异方差数据，用于测试wild boostrap
y=A*(1+exp(-b*x))+ep
fit_model <- function(x, y) {
  model <- nls(y ~ A * (1 + exp(-b * x)), start = list(A = 1, b = 1))
  A_hat <- coef(model)["A"]
  b_hat <- coef(model)["b"]
  sigma2_hat <- var(residuals(model))
  return(c(A_hat, b_hat, sigma2_hat))
}
#参数boostrap
B <- 1000 
bootstrap_estimates <- data.frame(A_es=0,b_es=0,v_es=0)
for(i in 1:B) {
  idx <- sample(1:n, n, replace = TRUE)
  x_boot <- x[idx]
  y_boot <- y[idx]
  bootstrap_estimates[i,] <- fit_model(x_boot, y_boot)
}
bootstrap_estimates|>summarise(se_A_boot=sd(A_es),se_b_boot=sd(b_es),se_sigma2_boot=sd(v_es),
                               bias_A_boot=mean(A_es-A),bias_b_boot=mean(b_es-b),bias_sigma2_boot=mean(v_es-v))
#对比:残差boostrap,假设残差独立同分布，异方差不适用,估计的方差更小
#首先估计残差
model <- nls(y ~ A * (1 + exp(-b * x)), start = list(A = 1, b = 1))
res <- residuals(model)
y_hat=predict(model,x)
B <- 1000 
bootstrap_estimates <- data.frame(A_es=0,b_es=0,v_es=0)
for(i in 1:B) {
  rr<- sample(res, n, replace = TRUE)
  y_new=y_hat+rr
  bootstrap_estimates[i,] <- fit_model(x, y_new)
}
bootstrap_estimates|>summarise(se_A_boot=sd(A_es),se_b_boot=sd(b_es),se_sigma2_boot=sd(v_es),
                               bias_A_boot=mean(A_es-A),bias_b_boot=mean(b_es-b),bias_sigma2_boot=mean(v_es-v))
#对比:wild boostrap
#对残差进行加权重采样，保留了原始残差的异方差结构
#以下生成的数据是针对异方差的数据，做一个尝试
model <- nls(y ~ A * (1 + exp(-b * x)), start = list(A = 1, b = 1))
res <- residuals(model)
y_hat=predict(model,x)
B <- 1000 
bootstrap_estimates <- data.frame(A_es=0,b_es=0,v_es=0)
for(i in 1:B) {
  rr<- sample(res, n, replace = TRUE)* sample(c(-1, 1), n, replace = TRUE)#加权重采样
  y_new=y_hat+rr
  bootstrap_estimates[i,] <- fit_model(x, y_new)
}
bootstrap_estimates|>summarise(se_A_boot=sd(A_es),se_b_boot=sd(b_es),se_sigma2_boot=sd(v_es),
                               bias_A_boot=mean(A_es-A),bias_b_boot=mean(b_es-b),bias_sigma2_boot=mean(v_es-v))
#在参数估计上，wild boostrap的方差会更小一些，但问题是偶尔会发生nls不收敛的情况
#第二问
B_rep <- 1000 
bootstrap_estimates <- data.frame(A_es=0,b_es=0,v_es=0)
for(i in 1:B_rep) {
  idx <- sample(1:n, n, replace = TRUE)
  x=seq(-10,10)
  n=length(x)
  ep=rnorm(n,0,v)
  y=A*(1+exp(-b*x))+ep
  bootstrap_estimates[i,] <- fit_model(x, y)
}
bootstrap_estimates|>summarise(se_A_boot=sd(A_es),se_b_boot=sd(b_es),se_sigma2_boot=sd(v_es),
                               bias_A_boot=mean(A_es-A),bias_b_boot=mean(b_es-b),bias_sigma2_boot=mean(v_es-v))
```


### 置信区间长度比较 

```{r}
N=1000
n=30
p=0.4
s=rbinom(N,n,p)
p_hat=s/n
alpha=0.05
f1 <- function(p_hat, n, alpha) {
  v <- sqrt(1/n * p_hat * (1 - p_hat))
  return(list(left = p_hat - qnorm(1 - alpha/2, 0, 1) * v,
              right = p_hat + qnorm(1 - alpha/2, 0, 1) * v))
}

f2=function(p_hat,n,alpha){
  s_sq=n/(n-1)*p_hat*(1-p_hat)
  z=qnorm(1 - alpha/2, 0, 1)
  return(list(left = p_hat - z*sqrt(1/n*s_sq),
              right = p_hat + z*sqrt(1/n*s_sq)))
}

f3=function(p_hat,n,alpha){
  z=qnorm(1 - alpha/2, 0, 1)
  mu=(p_hat+z^2/(2*n))/(1+z^2/n)
  se=sqrt(z^2/(4*n)+p_hat*(1-p_hat))/(sqrt(n)*(1+z^2/n))
  return(list(left=mu-z*se,right=mu+z*se))
}

f4=function(p_hat,n,alpha){
  z=qnorm(1 - alpha/2, 0, 1)
  mu=(p_hat+z^2/(2*n))/(1+z^2/n)
  se=sqrt(p_hat*(1-p_hat))/(sqrt(n)*(1+p_hat^2/n))
  return(list(left=mu-z*se,right=mu+z*se))
}

f5=function(s,n,alpha){
  left=(1+(n-s+1)/s*qf(1-alpha/2,2*(n-s+1),2*s))^(-1)
  right=(1+(n-s)/(s+1)/qf(1-alpha/2,2*(s+1),2*(n-s)))
  return(list(left=left,right=right))
}


interval=function(){
  f1_interval <- map_df(p_hat, ~ {
    ci <- f1(.x, n, alpha)
    data.frame(method='f1',left = ci$left, right = ci$right)
  })
  f2_interval <- map_df(p_hat, ~ {
    ci <- f2(.x, n, alpha)
    data.frame(method='f2',left = ci$left, right = ci$right)
  })
  f3_interval <- map_df(p_hat, ~ {
    ci <- f3(.x, n, alpha)
    data.frame(method='f3',left = ci$left, right = ci$right)
  })
  f4_interval <- map_df(p_hat, ~ {
    ci <- f4(.x, n, alpha)
    data.frame(method='f4',left = ci$left, right = ci$right)
  })
  s_valid<- s[s > 0 & s < n]
  f5_interval <- map_df(s_valid, ~ {
    ci <- f5(.x, n, alpha)
    data.frame(method='f5',left = ci$left, right = ci$right)
  })
  return(rbind(f1_interval,f2_interval,f3_interval,f4_interval,f5_interval))
}
estimate=interval()
#可视化置信区间
m='f3'
estimate %>% 
  ungroup() %>%
  filter(method == m) %>%  
  mutate(type = left <= p & right >= p) %>% 
  slice(1:100) %>% 
  mutate(id = row_number()) %>% 
  ggplot(aes(x = id)) +
  geom_segment(aes(x = id, xend = id, y = left, yend = right, color = type), 
               linewidth = 0.7) +
  geom_hline(yintercept = p, linetype = "dashed", color = "blue") +
  labs(title = paste0(m,'置信区间可视化'),
       x = "ID",
       y = "置信区间") +
  theme_minimal()+theme(legend.position = 'none')

#对每种方法都进行评价
com <- estimate |> 
  mutate(l = right - left, r = (right > p & left < p)) |> 
  group_by(method) |> 
  summarise(
    coverage = mean(r),  # 覆盖率
    avg_length = mean(l),  # 平均区间长度
    sd_length = sd(l),  # 区间长度的标准差
    .groups = "drop"  
  )
#-----------------------------------------------------
#把上面的过程整合成函数，对比分析
params <- expand.grid(
  p = c(0.1, 0.3, 0.5),      
  n = c(15, 30, 120,480),         
  alpha = c(0.01, 0.05, 0.1) 
)
compute_intervals <- function(p, n, alpha, N = 1000) {
  s <- rbinom(N, n, p)
  p_hat <- s / n
  
  # 计算所有方法的置信区间
  intervals <- list(
    f1 = map_df(p_hat, ~ {
      ci <- f1(.x, n, alpha)
      data.frame(method = "f1", left = ci$left, right = ci$right)
    }),
    f2 = map_df(p_hat, ~ {
      ci <- f2(.x, n, alpha)
      data.frame(method = "f2", left = ci$left, right = ci$right)
    }),
    f3 = map_df(p_hat, ~ {
      ci <- f3(.x, n, alpha)
      data.frame(method = "f3", left = ci$left, right = ci$right)
    }),
    f4 = map_df(p_hat, ~ {
      ci <- f4(.x, n, alpha)
      data.frame(method = "f4", left = ci$left, right = ci$right)
    }),
    f5 = map_df(s[s > 0 & s < n], ~ {
      ci <- f5(.x, n, alpha)
      data.frame(method = "f5", left = ci$left, right = ci$right)
    })
  ) |> bind_rows()
  
  # 计算覆盖率、区间长度等统计量
  intervals |> 
    mutate(
      l = right - left,
      r = (right > p & left < p)
    ) |> 
    group_by(method) |> 
    summarise(
      coverage = mean(r),
      avg_length = mean(l),
      sd_length = sd(l),
      .groups = "drop"
    ) |> 
    mutate(p = p, n = n, alpha = alpha)  
}
library(furrr) #并行计算
plan(multisession)

results <- future_pmap_dfr(
  params,
  ~ compute_intervals(p = ..1, n = ..2, alpha = ..3),
  .options = furrr_options(seed = 123),  
  .progress = TRUE
)
knitr::kable(head(results, 10))
```

### 习题23

Ising模型

```{r}
#习题23
# 设置参数
mu <- 1
n <- 5
iterations <- 10000  
burn_in <- 1000   
x <- sample(c(-1, 1), n, replace = TRUE)
samples <- matrix(NA, nrow =iterations-burn_in, ncol = n)

for (iter in 1:iterations) {
  for (i in 1:n) {
    x_proposal <- x
    x_proposal[i] <- -x_proposal[i]
    prev <- i - 1
    if (prev == 0) prev <- n
    next_ <- i + 1
    if (next_ > n) next_ <- 1
    delta_E <- 2 * mu * (x[i] * x[prev] + x[i] * x[next_])
    if (log(runif(1)) < -delta_E) {
      x <- x_proposal
    }
  }
  if (iter > burn_in) {
    samples[iter - burn_in, ] <- x
  }
}
```

